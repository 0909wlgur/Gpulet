Container nvidia build =  29224839
fp16 activated!
02/22/2024 07:56:10 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: True
02/22/2024 07:56:15 - INFO - __main__ -   USING CHECKPOINT from /workspace/bert/checkpoints/pytorch_model.bin
02/22/2024 07:56:16 - INFO - __main__ -   USED CHECKPOINT from /workspace/bert/checkpoints/pytorch_model.bin
02/22/2024 07:56:21 - INFO - __main__ -   using fp16
02/22/2024 07:56:21 - INFO - __main__ -   ***** Running evaluation *****
02/22/2024 07:56:21 - INFO - __main__ -     Num examples = 408
02/22/2024 07:56:21 - INFO - __main__ -     Batch size = 1
DLL 2024-02-22 07:56:10.304577 - PARAMETER Config : ["Namespace(amp=False, bert_model='bert-large-uncased', config_file='/workspace/bert/bert_configs/large.json', data_dir='/workspace/bert/data/download/glue/MRPC/', do_eval=False, do_lower_case=True, do_predict=True, do_train=False, eval_batch_size=1, fp16=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/bert/checkpoints/pytorch_model.bin', learning_rate=2.4e-05, local_rank=-1, loss_scale=0, max_seq_length=128, max_steps=1000.0, no_cuda=False, num_train_epochs=3.0, output_dir='/workspace/bert/results/MRPC', seed=1000, server_ip='', server_port='', skip_checkpoint=False, task_name='mrpc', train_batch_size=32, vocab_file='/workspace/bert/data/download/google_pretrained_weights/uncased_L-24_H-1024_A-16/vocab.txt', warmup_proportion=0.1)"] 
DLL 2024-02-22 07:56:10.304977 - PARAMETER SEED : 1000 
DLL 2024-02-22 07:56:16.282596 - PARAMETER num_parameters : 335150082 
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : False
master_weights         : True
loss_scale             : dynamic
Evaluating: 0it [00:00, ?it/s]Evaluating: 1it [00:02,  2.29s/it]Evaluating: 10it [00:02,  5.66it/s]Evaluating: 19it [00:02, 12.06it/s]Evaluating: 27it [00:02, 18.73it/s]Evaluating: 35it [00:02, 26.27it/s]Evaluating: 43it [00:02, 34.28it/s]Evaluating: 51it [00:02, 42.28it/s]Evaluating: 59it [00:03, 49.72it/s]Evaluating: 68it [00:03, 57.42it/s]Evaluating: 77it [00:03, 63.47it/s]Evaluating: 85it [00:03, 67.43it/s]Evaluating: 93it [00:03, 70.56it/s]Evaluating: 101it [00:03, 72.88it/s]Evaluating: 109it [00:03, 74.65it/s]Evaluating: 117it [00:03, 75.87it/s]Evaluating: 126it [00:03, 77.62it/s]Evaluating: 134it [00:03, 78.25it/s]Evaluating: 142it [00:04, 78.58it/s]Evaluating: 150it [00:04, 78.64it/s]Evaluating: 158it [00:04, 78.67it/s]Evaluating: 166it [00:04, 78.63it/s]Evaluating: 174it [00:04, 78.38it/s]Evaluating: 183it [00:04, 78.80it/s]Evaluating: 192it [00:04, 79.42it/s]Evaluating: 201it [00:04, 79.75it/s]Evaluating: 209it [00:04, 79.54it/s]Evaluating: 217it [00:04, 79.37it/s]Evaluating: 225it [00:05, 78.92it/s]Evaluating: 233it [00:05, 78.83it/s]Evaluating: 242it [00:05, 79.87it/s]Evaluating: 250it [00:05, 79.80it/s]Evaluating: 258it [00:05, 79.49it/s]Evaluating: 266it [00:05, 79.44it/s]Evaluating: 274it [00:05, 79.48it/s]Evaluating: 282it [00:05, 79.36it/s]Evaluating: 291it [00:05, 79.73it/s]Evaluating: 300it [00:06, 80.21it/s]Evaluating: 309it [00:06, 79.94it/s]Evaluating: 317it [00:06, 79.57it/s]Evaluating: 325it [00:06, 79.47it/s]Evaluating: 333it [00:06, 78.94it/s]Evaluating: 341it [00:06, 78.47it/s]Evaluating: 350it [00:06, 79.39it/s]Evaluating: 358it [00:06, 79.43it/s]Evaluating: 366it [00:06, 78.96it/s]Evaluating: 374it [00:06, 78.67it/s]Evaluating: 382it [00:07, 78.90it/s]Evaluating: 390it [00:07, 78.86it/s]Evaluating: 398it [00:07, 78.62it/s]Evaluating: 407it [00:07, 79.68it/s]Evaluating: 408it [00:07, 55.09it/s]
02/22/2024 07:56:29 - INFO - __main__ -   ***** Results *****
02/22/2024 07:56:29 - INFO - __main__ -     eval:num_samples_per_gpu = 408
02/22/2024 07:56:29 - INFO - __main__ -     eval:num_steps = 408
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):100% = 2289.85546875
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):50% = 12.228608131408691
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):90% = 12.759039878845215
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):95% = 12.890111923217773
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):99% = 13.174783706665039
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):avg = 17.847584586517485
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):std = 112.61979960081135
02/22/2024 07:56:29 - INFO - __main__ -     infer:latency(ms):sum = 7281.814511299133
02/22/2024 07:56:29 - INFO - __main__ -     infer:throughput(samples/s):avg = 56.02999078964586
DLL 2024-02-22 07:56:29.085241 -  e2e_inference_time : 7.2818145112991335 s
DLL 2024-02-22 07:56:29.085314 -  inference_sequences_per_second : 56.02999078964586 sequences/s
