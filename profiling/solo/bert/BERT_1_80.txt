Container nvidia build =  29224839
fp16 activated!
02/22/2024 07:57:42 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: True
02/22/2024 07:57:48 - INFO - __main__ -   USING CHECKPOINT from /workspace/bert/checkpoints/pytorch_model.bin
02/22/2024 07:57:48 - INFO - __main__ -   USED CHECKPOINT from /workspace/bert/checkpoints/pytorch_model.bin
02/22/2024 07:57:53 - INFO - __main__ -   using fp16
02/22/2024 07:57:54 - INFO - __main__ -   ***** Running evaluation *****
02/22/2024 07:57:54 - INFO - __main__ -     Num examples = 408
02/22/2024 07:57:54 - INFO - __main__ -     Batch size = 1
DLL 2024-02-22 07:57:42.574187 - PARAMETER Config : ["Namespace(amp=False, bert_model='bert-large-uncased', config_file='/workspace/bert/bert_configs/large.json', data_dir='/workspace/bert/data/download/glue/MRPC/', do_eval=False, do_lower_case=True, do_predict=True, do_train=False, eval_batch_size=1, fp16=True, gradient_accumulation_steps=1, init_checkpoint='/workspace/bert/checkpoints/pytorch_model.bin', learning_rate=2.4e-05, local_rank=-1, loss_scale=0, max_seq_length=128, max_steps=1000.0, no_cuda=False, num_train_epochs=3.0, output_dir='/workspace/bert/results/MRPC', seed=1000, server_ip='', server_port='', skip_checkpoint=False, task_name='mrpc', train_batch_size=32, vocab_file='/workspace/bert/data/download/google_pretrained_weights/uncased_L-24_H-1024_A-16/vocab.txt', warmup_proportion=0.1)"] 
DLL 2024-02-22 07:57:42.575091 - PARAMETER SEED : 1000 
DLL 2024-02-22 07:57:48.784929 - PARAMETER num_parameters : 335150082 
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : False
master_weights         : True
loss_scale             : dynamic
Evaluating: 0it [00:00, ?it/s]Evaluating: 1it [00:02,  2.28s/it]Evaluating: 9it [00:02,  5.11it/s]Evaluating: 17it [00:02, 10.88it/s]Evaluating: 25it [00:02, 17.70it/s]Evaluating: 33it [00:02, 25.36it/s]Evaluating: 41it [00:02, 33.39it/s]Evaluating: 49it [00:02, 41.13it/s]Evaluating: 57it [00:03, 47.93it/s]Evaluating: 65it [00:03, 54.54it/s]Evaluating: 73it [00:03, 60.38it/s]Evaluating: 81it [00:03, 64.52it/s]Evaluating: 89it [00:03, 67.86it/s]Evaluating: 97it [00:03, 70.45it/s]Evaluating: 105it [00:03, 72.34it/s]Evaluating: 113it [00:03, 73.53it/s]Evaluating: 122it [00:03, 75.79it/s]Evaluating: 130it [00:03, 76.52it/s]Evaluating: 138it [00:04, 76.02it/s]Evaluating: 146it [00:04, 75.72it/s]Evaluating: 154it [00:04, 75.59it/s]Evaluating: 162it [00:04, 75.24it/s]Evaluating: 170it [00:04, 75.69it/s]Evaluating: 178it [00:04, 75.76it/s]Evaluating: 186it [00:04, 76.53it/s]Evaluating: 194it [00:04, 76.98it/s]Evaluating: 202it [00:04, 77.14it/s]Evaluating: 210it [00:05, 77.04it/s]Evaluating: 218it [00:05, 77.19it/s]Evaluating: 226it [00:05, 77.37it/s]Evaluating: 234it [00:05, 78.13it/s]Evaluating: 242it [00:05, 77.92it/s]Evaluating: 250it [00:05, 78.10it/s]Evaluating: 258it [00:05, 77.78it/s]Evaluating: 266it [00:05, 77.36it/s]Evaluating: 274it [00:05, 77.07it/s]Evaluating: 282it [00:05, 76.90it/s]Evaluating: 290it [00:06, 77.01it/s]Evaluating: 298it [00:06, 77.69it/s]Evaluating: 306it [00:06, 77.88it/s]Evaluating: 314it [00:06, 78.15it/s]Evaluating: 322it [00:06, 78.19it/s]Evaluating: 330it [00:06, 78.25it/s]Evaluating: 338it [00:06, 77.99it/s]Evaluating: 346it [00:06, 78.43it/s]Evaluating: 354it [00:06, 78.66it/s]Evaluating: 362it [00:06, 78.83it/s]Evaluating: 370it [00:07, 78.42it/s]Evaluating: 378it [00:07, 77.95it/s]Evaluating: 386it [00:07, 77.65it/s]Evaluating: 394it [00:07, 78.08it/s]Evaluating: 402it [00:07, 77.67it/s]Evaluating: 408it [00:07, 54.08it/s]
02/22/2024 07:58:01 - INFO - __main__ -   ***** Results *****
02/22/2024 07:58:01 - INFO - __main__ -     eval:num_samples_per_gpu = 408
02/22/2024 07:58:01 - INFO - __main__ -     eval:num_steps = 408
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):100% = 2283.6796875
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):50% = 12.53990364074707
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):90% = 13.087743759155273
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):95% = 13.25875186920166
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):99% = 13.631487846374512
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):avg = 18.16691437889548
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):std = 112.29787005793632
02/22/2024 07:58:01 - INFO - __main__ -     infer:latency(ms):sum = 7412.1010665893555
02/22/2024 07:58:01 - INFO - __main__ -     infer:throughput(samples/s):avg = 55.04512098992996
DLL 2024-02-22 07:58:01.764802 -  e2e_inference_time : 7.412101066589355 s
DLL 2024-02-22 07:58:01.764872 -  inference_sequences_per_second : 55.04512098992996 sequences/s
